{
  "total_providers": 103,
  "providers": [
    "ai21",
    "ai21_chat",
    "aiohttp_openai",
    "aiml",
    "anthropic",
    "anthropic_text",
    "assemblyai",
    "auto_router",
    "azure",
    "azure_ai",
    "azure_text",
    "baseten",
    "bedrock",
    "bytez",
    "cerebras",
    "clarifai",
    "cloudflare",
    "codestral",
    "cohere",
    "cohere_chat",
    "cometapi",
    "compactifai",
    "custom",
    "custom_openai",
    "dashscope",
    "databricks",
    "datarobot",
    "deepgram",
    "deepinfra",
    "deepseek",
    "dotprompt",
    "elevenlabs",
    "empower",
    "fal_ai",
    "featherless_ai",
    "fireworks_ai",
    "friendliai",
    "galadriel",
    "gemini",
    "github",
    "github_copilot",
    "gradient_ai",
    "groq",
    "hosted_vllm",
    "huggingface",
    "humanloop",
    "hyperbolic",
    "infinity",
    "jina_ai",
    "langfuse",
    "lambda_ai",
    "lemonade",
    "llamafile",
    "litellm_proxy",
    "lm_studio",
    "maritalk",
    "meta_llama",
    "milvus",
    "mistral",
    "moonshot",
    "morph",
    "nebius",
    "nlp_cloud",
    "nscale",
    "novita",
    "nvidia_nim",
    "oci",
    "oobabooga",
    "ollama",
    "ollama_chat",
    "ollama_openai",
    "openai",
    "openai_like",
    "openrouter",
    "ovhcloud",
    "pg_vector",
    "predibase",
    "recraft",
    "replicate",
    "runwayml",
    "sagemaker",
    "sagemaker_chat",
    "sambanova",
    "snowflake",
    "text-completion-codestral",
    "text-completion-openai",
    "together_ai",
    "topaz",
    "triton",
    "v0",
    "vercel_ai_gateway",
    "vertex_ai",
    "vertex_ai_beta",
    "volcengine",
    "voyage",
    "vllm",
    "wandb",
    "watsonx",
    "watsonx_text",
    "xai",
    "xinference"
  ],
  "provider_details": {
    "ai21": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AI21 Labs API"
    },
    "ai21_chat": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AI21 Labs Chat API"
    },
    "aiohttp_openai": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "OpenAI-compatible API with aiohttp"
    },
    "aiml": {
      "model_count": 10,
      "sample_models": [
        "aiml/dall-e-2",
        "aiml/dall-e-3",
        "aiml/flux-pro"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AIML AI Platform"
    },
    "anthropic": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Anthropic Claude API"
    },
    "anthropic_text": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Anthropic Text Completions API"
    },
    "assemblyai": {
      "model_count": 2,
      "sample_models": [
        "assemblyai/best",
        "assemblyai/nano"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AssemblyAI Speech Recognition"
    },
    "auto_router": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "LiteLLM Auto Router"
    },
    "azure": {
      "model_count": 173,
      "sample_models": [
        "azure/ada",
        "azure/codex-mini",
        "azure/command-r-plus"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Azure OpenAI Service"
    },
    "azure_ai": {
      "model_count": 57,
      "sample_models": [
        "azure_ai/Cohere-embed-v3-english",
        "azure_ai/Cohere-embed-v3-multilingual",
        "azure_ai/FLUX-1.1-pro"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Azure AI Studio"
    },
    "azure_text": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Azure Text Completions API"
    },
    "baseten": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Baseten AI Platform"
    },
    "bedrock": {
      "model_count": 86,
      "sample_models": [
        "bedrock/*/1-month-commitment/cohere.command-light-text-v14",
        "bedrock/*/1-month-commitment/cohere.command-text-v14",
        "bedrock/*/6-month-commitment/cohere.command-light-text-v14"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AWS Bedrock"
    },
    "bytez": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Bytez AI Platform"
    },
    "cerebras": {
      "model_count": 5,
      "sample_models": [
        "cerebras/llama-3.3-70b",
        "cerebras/llama3.1-70b",
        "cerebras/llama3.1-8b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Cerebras Cloud Inference"
    },
    "clarifai": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Clarifai AI Platform"
    },
    "cloudflare": {
      "model_count": 4,
      "sample_models": [
        "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
        "cloudflare/@cf/meta/llama-2-7b-chat-int8",
        "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Cloudflare Workers AI"
    },
    "codestral": {
      "model_count": 2,
      "sample_models": [
        "codestral/codestral-2405",
        "codestral/codestral-latest"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Mistral Codestral API"
    },
    "cohere": {
      "model_count": 1,
      "sample_models": [
        "cohere/embed-v4.0"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Cohere AI"
    },
    "cohere_chat": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Cohere Chat API"
    },
    "cometapi": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Comet ML API"
    },
    "compactifai": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Compactifai Platform"
    },
    "custom": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Custom OpenAI-compatible API"
    },
    "custom_openai": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Custom OpenAI-compatible API (no auth required)"
    },
    "dashscope": {
      "model_count": 22,
      "sample_models": [
        "dashscope/qwen-coder",
        "dashscope/qwen-flash",
        "dashscope/qwen-flash-2025-07-28"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Alibaba DashScope"
    },
    "databricks": {
      "model_count": 11,
      "sample_models": [
        "databricks/databricks-bge-large-en",
        "databricks/databricks-claude-3-7-sonnet",
        "databricks/databricks-gte-large-en"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Databricks AI"
    },
    "datarobot": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "DataRobot AI Platform"
    },
    "deepgram": {
      "model_count": 36,
      "sample_models": [
        "deepgram/base",
        "deepgram/base-conversationalai",
        "deepgram/base-finance"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Deepgram Speech AI"
    },
    "deepinfra": {
      "model_count": 67,
      "sample_models": [
        "deepinfra/Gryphe/MythoMax-L2-13b",
        "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B",
        "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "DeepInfra AI"
    },
    "deepseek": {
      "model_count": 5,
      "sample_models": [
        "deepseek/deepseek-chat",
        "deepseek/deepseek-coder",
        "deepseek/deepseek-r1"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "DeepSeek AI"
    },
    "dotprompt": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "DotPrompt Platform"
    },
    "elevenlabs": {
      "model_count": 2,
      "sample_models": [
        "elevenlabs/scribe_v1",
        "elevenlabs/scribe_v1_experimental"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "ElevenLabs Speech AI"
    },
    "empower": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Empower AI Platform"
    },
    "fal_ai": {
      "model_count": 12,
      "sample_models": [
        "fal_ai/bria/text-to-image/3.2",
        "fal_ai/fal-ai/flux-pro/v1.1",
        "fal_ai/fal-ai/flux-pro/v1.1-ultra"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Fal.ai Platform"
    },
    "featherless_ai": {
      "model_count": 2,
      "sample_models": [
        "featherless_ai/featherless-ai/Qwerky-72B",
        "featherless_ai/featherless-ai/Qwerky-QwQ-32B"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Featherless AI"
    },
    "fireworks_ai": {
      "model_count": 32,
      "sample_models": [
        "fireworks_ai/WhereIsAI/UAE-Large-V1",
        "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
        "fireworks_ai/accounts/fireworks/models/deepseek-r1"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Fireworks AI"
    },
    "friendliai": {
      "model_count": 2,
      "sample_models": [
        "friendliai/meta-llama-3.1-70b-instruct",
        "friendliai/meta-llama-3.1-8b-instruct"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "FriendliAI Platform"
    },
    "galadriel": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Galadriel AI Platform"
    },
    "gemini": {
      "model_count": 64,
      "sample_models": [
        "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025",
        "gemini/gemini-embedding-001",
        "gemini/gemini-1.5-flash"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Google Gemini API"
    },
    "github": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "GitHub Models API"
    },
    "github_copilot": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "GitHub Copilot API"
    },
    "gradient_ai": {
      "model_count": 13,
      "sample_models": [
        "gradient_ai/alibaba-qwen3-32b",
        "gradient_ai/anthropic-claude-3-opus",
        "gradient_ai/anthropic-claude-3.5-haiku"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Gradient AI"
    },
    "groq": {
      "model_count": 31,
      "sample_models": [
        "groq/deepseek-r1-distill-llama-70b",
        "groq/distil-whisper-large-v3-en",
        "groq/gemma-7b-it"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Groq Fast AI Inference"
    },
    "hosted_vllm": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Hosted vLLM Instance"
    },
    "huggingface": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "HuggingFace Inference API"
    },
    "humanloop": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Humanloop Platform"
    },
    "hyperbolic": {
      "model_count": 16,
      "sample_models": [
        "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B",
        "hyperbolic/Qwen/QwQ-32B",
        "hyperbolic/Qwen/Qwen2.5-72B-Instruct"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Hyperbolic AI"
    },
    "infinity": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Infinity Platform"
    },
    "jina_ai": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Jina AI Platform"
    },
    "langfuse": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Langfuse Platform"
    },
    "lambda_ai": {
      "model_count": 20,
      "sample_models": [
        "lambda_ai/deepseek-llama3.3-70b",
        "lambda_ai/deepseek-r1-0528",
        "lambda_ai/deepseek-r1-671b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Lambda Labs AI"
    },
    "lemonade": {
      "model_count": 5,
      "sample_models": [
        "lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "lemonade/gpt-oss-20b-mxfp4-GGUF",
        "lemonade/gpt-oss-120b-mxfp-GGUF"
      ],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Lemonade instance - no API key required"
    },
    "llamafile": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Llamafile instance - no API key required"
    },
    "litellm_proxy": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "LiteLLM Proxy"
    },
    "lm_studio": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local LM Studio instance - no API key required",
      "default_base_url": "http://localhost:1234/v1"
    },
    "maritalk": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Maritalk AI"
    },
    "meta_llama": {
      "model_count": 4,
      "sample_models": [
        "meta_llama/Llama-3.3-70B-Instruct",
        "meta_llama/Llama-3.3-8B-Instruct",
        "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Meta Llama API"
    },
    "milvus": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Milvus Vector Database"
    },
    "mistral": {
      "model_count": 36,
      "sample_models": [
        "mistral/codestral-2405",
        "mistral/codestral-latest",
        "mistral/codestral-mamba-latest"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Mistral AI"
    },
    "moonshot": {
      "model_count": 17,
      "sample_models": [
        "moonshot/kimi-k2-0711-preview",
        "moonshot/kimi-latest",
        "moonshot/kimi-latest-128k"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Moonshot AI"
    },
    "morph": {
      "model_count": 2,
      "sample_models": [
        "morph/morph-v3-fast",
        "morph/morph-v3-large"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Morph AI"
    },
    "nebius": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Nebius AI Platform"
    },
    "nlp_cloud": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "NLP Cloud"
    },
    "nscale": {
      "model_count": 16,
      "sample_models": [
        "nscale/Qwen/QwQ-32B",
        "nscale/Qwen/Qwen2.5-Coder-32B-Instruct",
        "nscale/Qwen/Qwen2.5-Coder-3B-Instruct"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Nscale AI"
    },
    "novita": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Novita AI"
    },
    "nvidia_nim": {
      "model_count": 2,
      "sample_models": [
        "nvidia_nim/nvidia/nv-rerankqa-mistral-4b-v3",
        "nvidia_nim/nvidia/llama-3_2-nv-rerankqa-1b-v2"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "NVIDIA NIM"
    },
    "oci": {
      "model_count": 13,
      "sample_models": [
        "oci/meta.llama-3.1-405b-instruct",
        "oci/meta.llama-3.2-90b-vision-instruct",
        "oci/meta.llama-3.3-70b-instruct"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Oracle Cloud Infrastructure AI"
    },
    "oobabooga": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Oobabooga instance - no API key required"
    },
    "ollama": {
      "model_count": 29,
      "sample_models": [
        "qwen3:14b",
        "llama3.2:3b",
        "gemma3:latest"
      ],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Ollama instance - no API key required",
      "default_base_url": "http://localhost:11434"
    },
    "ollama_chat": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Ollama Chat instance - no API key required"
    },
    "ollama_openai": {
      "model_count": 29,
      "sample_models": [
        "qwen3:14b",
        "llama3.2:3b",
        "gemma3:latest"
      ],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Ollama via OpenAI-compatible API (supports function calling)",
      "default_base_url": "http://localhost:11434/v1"
    },
    "openai": {
      "model_count": 3,
      "sample_models": [
        "openai/container",
        "openai/sora-2",
        "openai/sora-2-pro"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "OpenAI API"
    },
    "openai_like": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "OpenAI-compatible API"
    },
    "openrouter": {
      "model_count": 91,
      "sample_models": [
        "openrouter/anthropic/claude-2",
        "openrouter/anthropic/claude-3-5-haiku",
        "openrouter/anthropic/claude-3-5-haiku-20241022"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "OpenRouter API"
    },
    "ovhcloud": {
      "model_count": 15,
      "sample_models": [
        "ovhcloud/DeepSeek-R1-Distill-Llama-70B",
        "ovhcloud/Llama-3.1-8B-Instruct",
        "ovhcloud/Meta-Llama-3_1-70B-Instruct"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "OVHcloud AI"
    },
    "pg_vector": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "pgvector Database"
    },
    "predibase": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Predibase Platform"
    },
    "recraft": {
      "model_count": 2,
      "sample_models": [
        "recraft/recraftv2",
        "recraft/recraftv3"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Recraft AI"
    },
    "replicate": {
      "model_count": 13,
      "sample_models": [
        "replicate/meta/llama-2-13b",
        "replicate/meta/llama-2-13b-chat",
        "replicate/meta/llama-2-70b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Replicate AI"
    },
    "runwayml": {
      "model_count": 6,
      "sample_models": [
        "runwayml/gen4_turbo",
        "runwayml/gen4_aleph",
        "runwayml/gen3a_turbo"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Runway ML"
    },
    "sagemaker": {
      "model_count": 6,
      "sample_models": [
        "sagemaker/meta-textgeneration-llama-2-13b",
        "sagemaker/meta-textgeneration-llama-2-13b-f",
        "sagemaker/meta-textgeneration-llama-2-70b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AWS SageMaker"
    },
    "sagemaker_chat": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "AWS SageMaker Chat"
    },
    "sambanova": {
      "model_count": 16,
      "sample_models": [
        "sambanova/DeepSeek-R1",
        "sambanova/DeepSeek-R1-Distill-Llama-70B",
        "sambanova/DeepSeek-V3-0324"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "SambaNova AI"
    },
    "snowflake": {
      "model_count": 24,
      "sample_models": [
        "snowflake/claude-3-5-sonnet",
        "snowflake/deepseek-r1",
        "snowflake/gemma-7b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Snowflake Cortex"
    },
    "text-completion-codestral": {
      "model_count": 2,
      "sample_models": [
        "text-completion-codestral/codestral-2405",
        "text-completion-codestral/codestral-latest"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Mistral Codestral Text Completions"
    },
    "text-completion-openai": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "OpenAI Text Completions API"
    },
    "together_ai": {
      "model_count": 31,
      "sample_models": [
        "together_ai/baai/bge-base-en-v1.5",
        "together_ai/BAAI/bge-base-en-v1.5",
        "together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Together AI"
    },
    "topaz": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Topaz AI"
    },
    "triton": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "NVIDIA Triton Inference Server"
    },
    "v0": {
      "model_count": 3,
      "sample_models": [
        "v0/v0-1.0-md",
        "v0/v0-1.5-lg",
        "v0/v0-1.5-md"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Vercel v0"
    },
    "vercel_ai_gateway": {
      "model_count": 91,
      "sample_models": [
        "vercel_ai_gateway/alibaba/qwen-3-14b",
        "vercel_ai_gateway/alibaba/qwen-3-235b",
        "vercel_ai_gateway/alibaba/qwen-3-30b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Vercel AI Gateway"
    },
    "vertex_ai": {
      "model_count": 86,
      "sample_models": [
        "vertex_ai/gemini-3-pro-preview",
        "vertex_ai/claude-3-5-haiku",
        "vertex_ai/claude-3-5-haiku@20241022"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Google Vertex AI"
    },
    "vertex_ai_beta": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Google Vertex AI Beta"
    },
    "volcengine": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Volcengine AI"
    },
    "voyage": {
      "model_count": 17,
      "sample_models": [
        "voyage/rerank-2",
        "voyage/rerank-2-lite",
        "voyage/voyage-2"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Voyage AI"
    },
    "vllm": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local vLLM instance - no API key required",
      "default_base_url": "http://localhost:8000/v1"
    },
    "wandb": {
      "model_count": 14,
      "sample_models": [
        "wandb/openai/gpt-oss-120b",
        "wandb/openai/gpt-oss-20b",
        "wandb/zai-org/GLM-4.5"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "Weights & Biases"
    },
    "watsonx": {
      "model_count": 28,
      "sample_models": [
        "watsonx/ibm/granite-3-8b-instruct",
        "watsonx/mistralai/mistral-large",
        "watsonx/bigscience/mt0-xxl-13b"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "IBM watsonx"
    },
    "watsonx_text": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "IBM watsonx Text Completions"
    },
    "xai": {
      "model_count": 27,
      "sample_models": [
        "xai/grok-2",
        "xai/grok-2-1212",
        "xai/grok-2-latest"
      ],
      "requires_auth": true,
      "auth_type": "Bearer Token",
      "provider_type": "remote",
      "description": "xAI Grok"
    },
    "xinference": {
      "model_count": 0,
      "sample_models": [],
      "requires_auth": false,
      "auth_type": "None",
      "provider_type": "local",
      "description": "Local Xorbits Inference instance - no API key required"
    }
  }
}
